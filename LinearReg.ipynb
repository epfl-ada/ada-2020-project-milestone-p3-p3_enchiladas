{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook of how linear regression can be added to the main code #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_LSOA_PATH = os.getcwd() + '/data/Geo_data/LSOA_2011_London_gen_MHW.shp'\n",
    "TESCO_PATH = os.getcwd() + '/data/Area_level_data/year_lsoa_grocery.csv'\n",
    "SOCIO_ECO_LSOA_PATH = os.getcwd() + '/data/lsoa-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_merge_clean_data(TESCO_PATH, SOCIO_ECO_LSOA_PATH, GEO_LSOA_PATH):\n",
    "    '''\n",
    "    This function load the different datasets used for the analysis,\n",
    "    clean and merge those datasets together to obtain as an output one single panda dataframe\n",
    "    with the socio-economic, the Tesco and the geography information of each LSOA\n",
    "    '''\n",
    "    # load the data with the geography information of each LSOA\n",
    "    map_df = gpd.read_file(GEO_LSOA_PATH)\n",
    "    # set the index of this dataframe to the code of each LSOA to facilitate the merge of the dataframes\n",
    "    map_df.index = map_df['LSOA11CD']\n",
    "    \n",
    "    # load the data with the Tesco information of each LSOA\n",
    "    data_df = pd.read_csv(TESCO_PATH)\n",
    "    \n",
    "    # merge the Tesco dataframe with the one with the geo information of the corresponding regions  \n",
    "    merged_map_df = map_df.join(data_df.set_index('area_id'))\n",
    "    \n",
    "    # convert coordinates that are in UTM format into latitude longitude (to plot the results on a map)\n",
    "    merged_map_df = merged_map_df.to_crs({'init': 'epsg:4326'}) # cause of the warning\n",
    "    \n",
    "    # load the data with the socio-economic information of each LSOA\n",
    "    lsoa_df = pd.read_csv(SOCIO_ECO_LSOA_PATH, encoding = \"ISO-8859-1\", engine='python')\n",
    "    # drop the last 2 rows that are full of nan (due to the format of the title of the columns (3 rows))\n",
    "    lsoa_df.drop(lsoa_df.tail(2).index,inplace=True)\n",
    "    \n",
    "    # merge the merged dataframe with  the socio-economic dataframe of the corresponding regions  \n",
    "    merged_map_lsoa_df = merged_map_df.join(lsoa_df.set_index('Lower Super Output Area'))\n",
    "    \n",
    "    # set the index of this dataframe to the name of each LSOA to obtain more comprehensive data\n",
    "    merged_map_lsoa_df.index = merged_map_lsoa_df['LSOA11NM']\n",
    "    \n",
    "    # remove the rows for which we don't have data everywhere \n",
    "    # consider the feature of population to determine where we lack some information\n",
    "    population = np.array((merged_map_lsoa_df['population'])) \n",
    "    merged_map_lsoa_df = merged_map_lsoa_df[np.logical_not(np.isnan(population))]\n",
    "    \n",
    "    # return this final merged and cleaned dataset\n",
    "    return merged_map_lsoa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_merge_clean_data(TESCO_PATH, SOCIO_ECO_LSOA_PATH, GEO_LSOA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>MSOA11CD</th>\n",
       "      <th>MSOA11NM</th>\n",
       "      <th>LAD11CD</th>\n",
       "      <th>LAD11NM</th>\n",
       "      <th>RGN11CD</th>\n",
       "      <th>RGN11NM</th>\n",
       "      <th>USUALRES</th>\n",
       "      <th>HHOLDRES</th>\n",
       "      <th>...</th>\n",
       "      <th>Road Casualties;2012;Slight</th>\n",
       "      <th>Road Casualties;2012;2012 Total</th>\n",
       "      <th>Road Casualties;2013;Fatal</th>\n",
       "      <th>Road Casualties;2013;Serious</th>\n",
       "      <th>Road Casualties;2013;Slight</th>\n",
       "      <th>Road Casualties;2013;2013 Total</th>\n",
       "      <th>Road Casualties;2014;Fatal</th>\n",
       "      <th>Road Casualties;2014;Serious</th>\n",
       "      <th>Road Casualties;2014;Slight</th>\n",
       "      <th>Road Casualties;2014;2014 Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>City of London 001A</th>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>London</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London 001B</th>\n",
       "      <td>E01000002</td>\n",
       "      <td>City of London 001B</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>London</td>\n",
       "      <td>1436</td>\n",
       "      <td>1436</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London 001C</th>\n",
       "      <td>E01000003</td>\n",
       "      <td>City of London 001C</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>London</td>\n",
       "      <td>1346</td>\n",
       "      <td>1250</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London 001E</th>\n",
       "      <td>E01000005</td>\n",
       "      <td>City of London 001E</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>London</td>\n",
       "      <td>985</td>\n",
       "      <td>985</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham 016A</th>\n",
       "      <td>E01000006</td>\n",
       "      <td>Barking and Dagenham 016A</td>\n",
       "      <td>E02000017</td>\n",
       "      <td>Barking and Dagenham 016</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>London</td>\n",
       "      <td>1703</td>\n",
       "      <td>1699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 492 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            LSOA11CD                   LSOA11NM   MSOA11CD  \\\n",
       "LSOA11NM                                                                     \n",
       "City of London 001A        E01000001        City of London 001A  E02000001   \n",
       "City of London 001B        E01000002        City of London 001B  E02000001   \n",
       "City of London 001C        E01000003        City of London 001C  E02000001   \n",
       "City of London 001E        E01000005        City of London 001E  E02000001   \n",
       "Barking and Dagenham 016A  E01000006  Barking and Dagenham 016A  E02000017   \n",
       "\n",
       "                                           MSOA11NM    LAD11CD  \\\n",
       "LSOA11NM                                                         \n",
       "City of London 001A              City of London 001  E09000001   \n",
       "City of London 001B              City of London 001  E09000001   \n",
       "City of London 001C              City of London 001  E09000001   \n",
       "City of London 001E              City of London 001  E09000001   \n",
       "Barking and Dagenham 016A  Barking and Dagenham 016  E09000002   \n",
       "\n",
       "                                        LAD11NM    RGN11CD RGN11NM  USUALRES  \\\n",
       "LSOA11NM                                                                       \n",
       "City of London 001A              City of London  E12000007  London      1465   \n",
       "City of London 001B              City of London  E12000007  London      1436   \n",
       "City of London 001C              City of London  E12000007  London      1346   \n",
       "City of London 001E              City of London  E12000007  London       985   \n",
       "Barking and Dagenham 016A  Barking and Dagenham  E12000007  London      1703   \n",
       "\n",
       "                           HHOLDRES  ...  Road Casualties;2012;Slight  \\\n",
       "LSOA11NM                             ...                                \n",
       "City of London 001A            1465  ...                         14.0   \n",
       "City of London 001B            1436  ...                          8.0   \n",
       "City of London 001C            1250  ...                          2.0   \n",
       "City of London 001E             985  ...                         22.0   \n",
       "Barking and Dagenham 016A      1699  ...                          0.0   \n",
       "\n",
       "                           Road Casualties;2012;2012 Total  \\\n",
       "LSOA11NM                                                     \n",
       "City of London 001A                                   16.0   \n",
       "City of London 001B                                    9.0   \n",
       "City of London 001C                                    2.0   \n",
       "City of London 001E                                   24.0   \n",
       "Barking and Dagenham 016A                              0.0   \n",
       "\n",
       "                           Road Casualties;2013;Fatal  \\\n",
       "LSOA11NM                                                \n",
       "City of London 001A                               0.0   \n",
       "City of London 001B                               0.0   \n",
       "City of London 001C                               0.0   \n",
       "City of London 001E                               0.0   \n",
       "Barking and Dagenham 016A                         0.0   \n",
       "\n",
       "                           Road Casualties;2013;Serious  \\\n",
       "LSOA11NM                                                  \n",
       "City of London 001A                                 3.0   \n",
       "City of London 001B                                 1.0   \n",
       "City of London 001C                                 0.0   \n",
       "City of London 001E                                 5.0   \n",
       "Barking and Dagenham 016A                           0.0   \n",
       "\n",
       "                          Road Casualties;2013;Slight  \\\n",
       "LSOA11NM                                                \n",
       "City of London 001A                              10.0   \n",
       "City of London 001B                               5.0   \n",
       "City of London 001C                               0.0   \n",
       "City of London 001E                              15.0   \n",
       "Barking and Dagenham 016A                         4.0   \n",
       "\n",
       "                           Road Casualties;2013;2013 Total  \\\n",
       "LSOA11NM                                                     \n",
       "City of London 001A                                   13.0   \n",
       "City of London 001B                                    6.0   \n",
       "City of London 001C                                    0.0   \n",
       "City of London 001E                                   20.0   \n",
       "Barking and Dagenham 016A                              4.0   \n",
       "\n",
       "                           Road Casualties;2014;Fatal  \\\n",
       "LSOA11NM                                                \n",
       "City of London 001A                               0.0   \n",
       "City of London 001B                               0.0   \n",
       "City of London 001C                               0.0   \n",
       "City of London 001E                               1.0   \n",
       "Barking and Dagenham 016A                         0.0   \n",
       "\n",
       "                           Road Casualties;2014;Serious  \\\n",
       "LSOA11NM                                                  \n",
       "City of London 001A                                 2.0   \n",
       "City of London 001B                                 0.0   \n",
       "City of London 001C                                 0.0   \n",
       "City of London 001E                                 0.0   \n",
       "Barking and Dagenham 016A                           0.0   \n",
       "\n",
       "                           Road Casualties;2014;Slight  \\\n",
       "LSOA11NM                                                 \n",
       "City of London 001A                               10.0   \n",
       "City of London 001B                                9.0   \n",
       "City of London 001C                                2.0   \n",
       "City of London 001E                               20.0   \n",
       "Barking and Dagenham 016A                          3.0   \n",
       "\n",
       "                           Road Casualties;2014;2014 Total  \n",
       "LSOA11NM                                                    \n",
       "City of London 001A                                   12.0  \n",
       "City of London 001B                                    9.0  \n",
       "City of London 001C                                    2.0  \n",
       "City of London 001E                                   21.0  \n",
       "Barking and Dagenham 016A                              3.0  \n",
       "\n",
       "[5 rows x 492 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the features of interest ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_activ = df['Economic Activity;Employment Rate;2011']\n",
    "eco_activ_stand = (eco_activ - np.mean(eco_activ))/np.std(eco_activ)\n",
    "\n",
    "income = df['Household Income, 2011/12;Median Annual Household Income estimate (£)']\n",
    "income_stand = (income - np.mean(income))/np.std(income)\n",
    "\n",
    "age = df['avg_age']\n",
    "age_stand = (age - np.mean(age))/np.std(age)\n",
    "\n",
    "h_items = df['h_items_norm']\n",
    "h_items_stand = (h_items - np.mean(h_items))/np.std(h_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_feats = ['Ethnic Group;Mixed/multiple ethnic groups (%);2011', \n",
    "                   'Ethnic Group;Asian/Asian British (%);2011', \n",
    "                   'Ethnic Group;Black/African/Caribbean/Black British (%);2011', \n",
    "                   'Ethnic Group;Other ethnic group (%);2011']\n",
    "h_ethnicity = 0\n",
    "for feat in diversity_feats:\n",
    "    val_feat = df[feat]/100\n",
    "    h_ethnicity += -val_feat * np.log2(val_feat+0.001)\n",
    "h_ethnicity = h_ethnicity/np.log2(4)\n",
    "\n",
    "h_ethnicity_stand = (h_ethnicity - np.mean(h_ethnicity))/np.std(h_ethnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eco</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>h_items</th>\n",
       "      <th>h_ethnicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>City of London 001A</th>\n",
       "      <td>1.465458</td>\n",
       "      <td>1.971130</td>\n",
       "      <td>3.214820</td>\n",
       "      <td>-1.382446</td>\n",
       "      <td>-1.344442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London 001B</th>\n",
       "      <td>1.453738</td>\n",
       "      <td>1.867475</td>\n",
       "      <td>2.976434</td>\n",
       "      <td>-1.104701</td>\n",
       "      <td>-1.900963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London 001C</th>\n",
       "      <td>0.563031</td>\n",
       "      <td>-0.119432</td>\n",
       "      <td>3.232598</td>\n",
       "      <td>0.359911</td>\n",
       "      <td>-0.762202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London 001E</th>\n",
       "      <td>-0.409714</td>\n",
       "      <td>-1.025721</td>\n",
       "      <td>-0.162352</td>\n",
       "      <td>-0.182977</td>\n",
       "      <td>0.932069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham 016A</th>\n",
       "      <td>-0.444873</td>\n",
       "      <td>0.295365</td>\n",
       "      <td>-1.102792</td>\n",
       "      <td>-0.245228</td>\n",
       "      <td>0.398236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                eco    income       age   h_items  h_ethnicity\n",
       "LSOA11NM                                                                      \n",
       "City of London 001A        1.465458  1.971130  3.214820 -1.382446    -1.344442\n",
       "City of London 001B        1.453738  1.867475  2.976434 -1.104701    -1.900963\n",
       "City of London 001C        0.563031 -0.119432  3.232598  0.359911    -0.762202\n",
       "City of London 001E       -0.409714 -1.025721 -0.162352 -0.182977     0.932069\n",
       "Barking and Dagenham 016A -0.444873  0.295365 -1.102792 -0.245228     0.398236"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stand_df = pd.DataFrame()\n",
    "stand_df['eco'] = eco_activ_stand\n",
    "stand_df['income'] = income_stand\n",
    "stand_df['age'] = age_stand\n",
    "stand_df['h_items'] = h_items_stand\n",
    "stand_df['h_ethnicity'] = h_ethnicity_stand\n",
    "#stand_df['h_ethni_bin'] = [1 if eth > np.median(h_ethnicity) else 0 for eth in h_ethnicity]\n",
    "stand_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting food consumption diversity using linear regression ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will try to keep only the ethnic entropy (`h_ethnicity`) to try to explain the food consumption entropy (`items`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ethnic entropy explains 12.90 % of the variance of the food consumption entropy.\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(stand_df, test_size=0.3, random_state=42)\n",
    "\n",
    "feature_cols = ['h_ethnicity']\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "X_test = test_df[feature_cols]\n",
    "y_train = train_df['h_items']\n",
    "y_test = test_df['h_items']\n",
    "\n",
    "lin_reg = LinearRegression()  # create the model\n",
    "lin_reg.fit(X_train, y_train)  # train\n",
    "y_pred_test = lin_reg.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print('The ethnic entropy explains {0:.2f} % of the variance of the food consumption entropy.'\n",
    "      .format(r2_test*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to explain the variance in the food consumption entropy (`h_items`) with the following features of each LSOA:\n",
    "- The ethnic entropy: `h_ethnicity`\n",
    "- The employment rate: `eco`\n",
    "- The average age: `age`\n",
    "- The average income per household: `income`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature columns used here explain 19.88 % of the variance of the food consumption entropy.\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['eco', 'income', 'age', 'h_ethnicity']\n",
    "\n",
    "# Linear regression with random split\n",
    "X_train = train_df[feature_cols]\n",
    "X_test = test_df[feature_cols]\n",
    "y_train = train_df['h_items']\n",
    "y_test = test_df['h_items']\n",
    "\n",
    "lin_reg = LinearRegression()  # create the model\n",
    "lin_reg.fit(X_train, y_train)  # train\n",
    "y_pred_test = lin_reg.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print('The feature columns used here explain {0:.2f} % of the variance of the food consumption entropy.'\n",
    "      .format(r2_test*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When adding the employment rate, the median household income and the average age of the LSOA's population in the predicting factors, $R^2$ only rises from 12.9 to 19.9 \\%. This seems to suggest that the ethnic entropy has a non-negligible effect on the food category entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the statsmodels module, and summarize the results to see the contribution and significance of each term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                h_items   R-squared:                       0.186\n",
      "Model:                            OLS   Adj. R-squared:                  0.186\n",
      "Method:                 Least Squares   F-statistic:                     276.2\n",
      "Date:                Tue, 08 Dec 2020   Prob (F-statistic):          4.11e-214\n",
      "Time:                        22:02:35   Log-Likelihood:                -6359.8\n",
      "No. Observations:                4833   AIC:                         1.273e+04\n",
      "Df Residuals:                    4828   BIC:                         1.276e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept    1.323e-15      0.013   1.02e-13      1.000      -0.025       0.025\n",
      "h_ethnicity     0.2184      0.018     12.255      0.000       0.183       0.253\n",
      "eco             0.1899      0.018     10.809      0.000       0.155       0.224\n",
      "age            -0.0743      0.016     -4.592      0.000      -0.106      -0.043\n",
      "income         -0.3325      0.018    -18.083      0.000      -0.369      -0.296\n",
      "==============================================================================\n",
      "Omnibus:                     1676.775   Durbin-Watson:                   1.255\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14263.119\n",
      "Skew:                          -1.415   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.926   Cond. No.                         2.74\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "formula = 'h_items ~ h_ethnicity + eco + age + income'\n",
    "\n",
    "mod = smf.ols(formula=formula, data=stand_df)\n",
    "np.random.seed(2)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these results, it looks like all four predictive factors have a significant effect on the food category entropy. They suggest the following conclusions:\n",
    "- LSOA with more ethnic diversity tend to have a larger food consumption diversity\n",
    "- LSOA with a higher employment rate tend to have a larger food consumption diversity\n",
    "- LSOA with a higher average age tend to have a lower food consumption diversity\n",
    "- LSOA with a larger median income per household tend to have a lower food consumption diversity\n",
    "\n",
    "As the features are standardized, the magnitude of their coefficients can be directly compared. This suggests that `income` impacts `h_items` the most, followed by `h_ethnicity`, `eco` and finally `age`. Even though it seems that ethnic diversity has an effect on food consumption diversity in an LSOA, we still need to be careful with the conclusions we might take here. Indeed, we could be in a situation where for example the `income` feature is a confounder and therefore it influences both `h_items` and `h_ethnicity`. We could therefore see an effect of `h_ethnicity` on `h_items`, even though it is actually `income` which impacts both indirectly. In this case, the effect of `h_ethnicity` on `h_items` could entirely be explained by `income`. To ensure that we are not in such a situation, we will use the notion of matching. We will first create a binary feature from `h_ethnicity` to divide the dataset in two groups. We will then perform a matching between these two groups, using the concept of propensity score. This will allow us to compare similar sets of samples and to get more insight on the effect of the ethnic diversity on the food consumption diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Geopandas_env) new try",
   "language": "python",
   "name": "geopandas_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
